{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Intro to Hypothesis Testing</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: our first hypothesis test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You find a brain in the human dissection lab, but you suspect it may belong to a new unknown species.\n",
    "\n",
    "You decide that mass of brain is the only important feature. So you will measure its mass, then compare it to an online database of all human brain masses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you measure the mass of the brain, and record it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_brain_mass = 1564.2 # grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you download your dataset and load it into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1031.03862494 1132.34383661 1188.58290064 ... 1325.03535947 1342.84315573\n",
      " 1578.74968743]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "brain_masses = np.load('human_brain_masses.npy')\n",
    "print(brain_masses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Does our sample brain come from a different *population* than the brains in this list of human brain masses?__  \n",
    "*(it's worth noting, though okay to ignore for now, that we are treating these brain measurements as a __population__ and not a sample from a larger population–we'll deal with this later)*  \n",
    "\n",
    "How can we answer that question?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Intuitive approach: \n",
    "\n",
    "Is our brain smaller than the largest human brain?  \n",
    "Is it larger than the smallest human brain?  \n",
    "Is it larger or smaller than the average human brain?  \n",
    "How many human brains are larger than our sample?  \n",
    "How many are smaller? </i>\n",
    "\n",
    "__Task__:  \n",
    "Answer these questions using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251206 are heavier than our sample brain.\n"
     ]
    }
   ],
   "source": [
    "# answer here\n",
    "is_heaver = brain_masses > sample_brain_mass\n",
    "\n",
    "number_of_heavier_brains = np.sum(is_heaver)\n",
    "\n",
    "print(f'{number_of_heavier_brains} are heavier than our sample brain.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.3 ms ± 1.91 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.sum(brain_masses>sample_brain_mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-3323d39b1d37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# this is convenient but possibly confusing for new programmers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbrain_masses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mbrain_masses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# it is simpler to *always* use this:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "# this is convenient but possibly confusing for new programmers\n",
    "for i in brain_masses:\n",
    "    brain_masses[i]\n",
    "    \n",
    "# it is simpler to *always* use this:\n",
    "for i in range(len(brain_masses)):\n",
    "    this_brain = brain_masses[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could ask hundreds of such questions. Visualization can help speed this up.\n",
    "\n",
    "__Task__:  \n",
    "(1) plot a histogram of the human brain mass dataset  \n",
    "(2) label the mean human brain and our sample brain on that histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x1c28fc5358>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer here\n",
    "\n",
    "fig,ax = pl.subplots(figsize=(12,7))\n",
    "fontsize = 'x-large'\n",
    "\n",
    "\n",
    "# show a histogram of all brain masses\n",
    "hvals,hbins,hps = ax.hist(brain_masses, bins=500, histtype='step', linewidth=2, color='grey')\n",
    "ax.set_xlabel('Brain mass (g)', fontsize=fontsize)\n",
    "ax.set_ylabel('Number of brains', fontsize=fontsize)\n",
    "ax.set_title('Human population brain masses', fontsize=fontsize, pad=60, color='grey')\n",
    "\n",
    "mean_human_brain_mass = np.mean(brain_masses)\n",
    "ax.axvline(mean_human_brain_mass, color='darkblue')\n",
    "ax.text(mean_human_brain_mass+20, 10000, 'Average\\nbrain', color='darkblue', fontsize=fontsize)\n",
    "\n",
    "# display our sample brain mass on the histogram\n",
    "ax.axvline(sample_brain_mass, color='darkmagenta')\n",
    "ax.text(1580, 30000, 'Sample\\nbrain', color='darkmagenta', fontsize=fontsize)\n",
    "\n",
    "delta = sample_brain_mass - mean_human_brain_mass \n",
    "ax.hlines(65000, mean_human_brain_mass, sample_brain_mass, color='darkgray')\n",
    "ax.text((mean_human_brain_mass+sample_brain_mass)/2, 66000, f'{delta:0.2f} g', color='darkgray', fontsize=fontsize, ha='center')\n",
    "\n",
    "hbins = (hbins[1:]+hbins[:-1])/2 # bin centers\n",
    "fill_xs = hbins[hbins>=sample_brain_mass]\n",
    "fill_ys = hvals[hbins>=sample_brain_mass]\n",
    "ax.fill_between(fill_xs, fill_ys, color='grey')\n",
    "\n",
    "# two-tailed\n",
    "ax.hlines(65000, mean_human_brain_mass-delta, mean_human_brain_mass, color='darkgray')\n",
    "ax.text(mean_human_brain_mass-delta/2, 66000, f'{delta:0.2f} g', color='darkgray', fontsize=fontsize, ha='center')\n",
    "fill_xs = hbins[hbins<=mean_human_brain_mass-delta]\n",
    "fill_ys = hvals[hbins<=mean_human_brain_mass-delta]\n",
    "ax.fill_between(fill_xs, fill_ys, color='grey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it's not possible to be *certain* about the answer to our question, we can judge *how likely* it is that our brain came from this population distribution.\n",
    "\n",
    "One measure of that is the fraction of brains that are __further from the mean__ than our sample is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task:__  \n",
    "(1) Compute the *fraction* of human brains with a mass larger than our sample brain.  \n",
    "(2) Compute the *fraction* of human brains with a mass *further from the mean* than our sample brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03588657655522522\n"
     ]
    }
   ],
   "source": [
    "# answer here\n",
    "\n",
    "is_heaver = brain_masses > sample_brain_mass\n",
    "\n",
    "number_of_heavier_brains = np.sum(is_heaver)\n",
    "\n",
    "fraction_of_heavier_brains = number_of_heavier_brains / len(brain_masses)\n",
    "\n",
    "print(fraction_of_heavier_brains)\n",
    "\n",
    "fraction_of_more_extreme_brains = fraction_of_heavier_brains*2\n",
    "#print(fraction_of_more_extreme_brains)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could rephrase the latter fraction as \"the probability of finding a brain with a more outlying mass than our sample.\"  \n",
    "This is often referred to as a \"p-value.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first value is a \"one-tailed\" value, and the second is a \"two-tailed\" value. Unless you have strong reason to believe your sample could not have been extreme in other direction (in our case, lighter), then it makes most sense to use a two-tailed test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "### Generalizing the approach\n",
    "\n",
    "If we can *assume* that the population underlying our data are *normally distributed*, then we can make that analysis very general.\n",
    "\n",
    "(Recall the <a href=\"https://en.wikipedia.org/wiki/Central_limit_theorem\">central limit theorem</a> for some basic intuition on the generality of normal distributions.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see why, let's visualize the basic properties of a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "xs = np.linspace(-4,4,1000)\n",
    "ys = norm.pdf(xs, 0, 1)\n",
    "\n",
    "fig,ax = pl.subplots()\n",
    "\n",
    "ax.plot(xs, ys, color='k', lw=2)\n",
    "\n",
    "for i,col in zip([3, 2.5, 2, 1], [.9, .8, .7, .6]):\n",
    "    use = (xs>0) & (xs<i)\n",
    "    ax.fill_between(xs[use], ys[use], color=pl.cm.Greys(col), lw=0)\n",
    "    ax.annotate(f'{i} std', [np.max(xs[use])+.15,np.min(ys[use])+.01], color=pl.cm.Greys(col), ha='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help illustrate the value of understanding this point, consider what happens when we choose to show our data in an arbitrary new unit of measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = pl.subplots(2,1,figsize=(5,7), sharex=True)\n",
    "\n",
    "for ax,scale,unit in zip(axs, [1,0.035274], ['g','oz']):\n",
    "    ax.hist(brain_masses*scale, color='k', bins=500, histtype='step')\n",
    "    ax.set_xlabel(f'Brain mass ({unit})')\n",
    "    ax.set_yticks([])\n",
    "    ax.axvline(sample_brain_mass*scale, color='darkmagenta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1292.0229673451206\n",
      "151.17544116993284\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(brain_masses)\n",
    "std = np.std(brain_masses)\n",
    "\n",
    "print(mean)\n",
    "print(std)\n",
    "\n",
    "relative_to_mean_in_grams = (brain_masses - mean)\n",
    "relative_to_mean_in_std_units = relative_to_mean_in_grams / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Mean subtracted and divded by std')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig,axs = pl.subplots(1,3)\n",
    "\n",
    "axs[0].hist(brain_masses, bins=100)\n",
    "axs[0].set_title('Original')\n",
    "axs[1].hist(relative_to_mean_in_grams, bins=100)\n",
    "axs[1].set_title('Mean subtracted')\n",
    "axs[2].hist(relative_to_mean_in_std_units, bins=100)\n",
    "axs[2].set_title('Mean subtracted and divded by std')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are identical, but if we didn't know that, it would not be immediately obvious how much of an \"outlier\" each one is, because the units are different.  \n",
    "\n",
    "To get around this, we normalize our measurements by subtracting the mean and dividing by standard deviation to produce a __z-score__.  \n",
    "<br>\n",
    "<center>$z = \\frac{\\text{sample value - population mean}}{\\text{population standard deviation}}$</center>\n",
    "\n",
    "<br>\n",
    "<center>$z = \\frac{x-\\mu}{\\sigma}$</center>\n",
    "\n",
    "\n",
    "where $x$ is our sample value, $\\mu$ is the population mean, and $\\sigma$ is the population standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.72636733, -1.05625047, -0.68423856, ...,  0.2183714 ,\n",
       "        0.33616696,  1.89664881])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_masses\n",
    "\n",
    "mean = brain_masses.mean()\n",
    "std = brain_masses.std()\n",
    "\n",
    "zscores = (brain_masses-mean)/(std)\n",
    "\n",
    "zscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task__: compute the z-score for every brain in our dataset, and for the sample brain, and display them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8004050826544735\n"
     ]
    }
   ],
   "source": [
    "zscore_of_sample_brain = (sample_brain_mass - mean) / std\n",
    "\n",
    "print(zscore_of_sample_brain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of values once z-scored is called the <u>*standard* normal distribution</u>, and it has a mean of 0 and a standard deviation of 1. \n",
    "\n",
    "We can use this system to express in general terms (a) how much of an outlier a data point is (ex. \"1.2 standard deviations from the mean\"), and (b) how likely that data point was to have arisen from the population (this is related to the p-value we saw above).\n",
    "\n",
    "We can use existing packages in Python to determine the probability of observing any given data point in a normal distribution. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8004049540540876\n",
      "0.07179671915293835\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm # norm is the normal distribution\n",
    "\n",
    "z_score = (sample_brain_mass-mean_human_brain_mass) / np.std(brain_masses, ddof=1)\n",
    "\n",
    "p = norm.sf(z_score) # survival function: returns the fraction of the distribution that is greater than the input value \n",
    "# (and it uses the standard normal distribution by default)\n",
    "\n",
    "print(z_score)\n",
    "print(p*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "### Putting it all together: conducting a hypothesis test\n",
    "\n",
    "__Null hypothesis__: our sample brain comes from the population of human brains  \n",
    "__Alternative hypothesis__: our sample brain comes from a separate population of brains  \n",
    "\n",
    "__Compute z-score__  \n",
    "__Compute p-value__  \n",
    "__Compute \"effect size\"__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What reasonable conclusions can make from this analysis? \n",
    "\n",
    "*What does the p-value tell us? What does it not tell us?*\n",
    "\n",
    "*One caveat*: This is also quite an odd scenario in reality, because we rarely have information about full *populations* and single data points to compare them to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: dealing with samples of multiple observations\n",
    "\n",
    "We often want to know about a *group of sampled points* as opposed to a single point.  \n",
    "A common example would be to ask \"does this sample come from a population with a mean of X?\" \n",
    "\n",
    "This has a similar flavor to our first example question. It's a bit more complex, but the same logic applies.\n",
    "\n",
    "Let's begin by loading in a similar dataset, but this time consisting of a set of sampled observations.  \n",
    "Suppose each sample represents the mean firing rate of a single neuron.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 19.08765187  68.65806486  33.56354929  32.49577301  30.48491205\n",
      "   9.27890057  27.96165612  -3.17118488  19.24172174  35.57012565\n",
      "   3.46882322  33.69680934  29.00681338  26.24718219  34.13053343\n",
      "  82.60800516  72.86523956  63.62233261  53.87813344  -2.98364416\n",
      "   2.923537    52.54128835   9.43490808  61.32799195   4.09816448\n",
      "  88.87137507  36.40587655  46.21497085 -19.43758789  20.50959796\n",
      " -44.17382065  22.16441264  -1.10324205 -13.17386638  42.25494227\n",
      "  27.17121254  94.43270511 -41.27862449  35.76603664  42.72439828\n",
      " -17.77928443 -58.33710308  42.46037535  51.20356776  65.45432975\n",
      "  37.14975646   0.503567    54.79503172  34.73825892 -24.52529967\n",
      "  13.70100255  14.9085       4.30102928 -26.74032759  63.57866916\n",
      " 100.64613485  53.43042129  59.48199558 -22.85693732  13.48268966\n",
      " -27.91227646  -0.54621774  56.90457851  24.52251321  58.36478292\n",
      "  49.79139193  38.61330352  36.20647124  -0.23270032  55.51730976\n",
      "   4.61814591  74.60904414   6.19978153  24.11885351 -28.61337162\n",
      "  -1.32663502  40.71207735  76.76817256  22.92906206  16.21432084\n",
      " -24.16177401  26.53378497  12.00422091  64.31092013   4.1792906\n",
      "  95.53059147  46.54118424  39.85992124  35.67754714  46.45533629\n",
      "  -0.7171342   81.79539757 -20.42160518   5.68593726  -9.45393747\n",
      " -23.88626546  36.00012173 -14.84516246  28.89370666  52.8690389\n",
      "  74.3129809   33.03282881  24.19591884  24.53749305 -16.16507378\n",
      "  68.80438552  11.82147498  -1.92261506  44.08131527  32.46683999\n",
      "  13.76677877   5.5412133   48.21830143  45.77237544  20.35519523\n",
      "  41.23526278  33.22448438  42.12667807  40.43332464  50.56616734]\n"
     ]
    }
   ],
   "source": [
    "sample = np.load('sample.npy')\n",
    "\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Number of neurons')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig,ax = pl.subplots()\n",
    "\n",
    "ax.hist(sample)\n",
    "ax.set_xlabel('Mean relative firing rate (Hz)')\n",
    "ax.set_ylabel('Number of neurons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We suspect that these neurons come from a neuronal population that has a mean firing rate of 30 Hz.\n",
    "\n",
    "Null hypothesis: the sample comes from a population with a mean of 30.  \n",
    "Alternative hypothesis: the sample comes from a population with a mean not equal to 30.\n",
    "\n",
    "__Task__: inspect these data and speculate on how you might answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "27.030809250655714\n"
     ]
    }
   ],
   "source": [
    "# inspect here\n",
    "print(len(sample))\n",
    "\n",
    "print(np.mean(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A naïve idea:* compute the sample mean, and if it differs from 30, reject the null hypothesis.\n",
    "\n",
    "This and many other simple approaches don't work because we don't know __what to expect by chance when sampling a set of points from a population__. In other words, we haven't specified our *null distribution* (i.e. the one we conveniently had available in the previous example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual demonstration\n",
    "\n",
    "fig,ax = pl.subplots()\n",
    "\n",
    "xs = np.arange(15,45,.01)\n",
    "ys = norm.pdf(xs, 30, 5)\n",
    "ax.plot(xs, ys, color='black', label='Population')\n",
    "ax.axvline(30, lw=4, color='k')\n",
    "ax.legend(loc='upper left')\n",
    "pl.waitforbuttonpress()\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "for i,col in enumerate(['maroon','darkorange','forestgreen','steelblue','violet','grey']):\n",
    "    sample = np.random.normal(30, 5, size=20)\n",
    "    ax2.hist(sample, bins=8, density=True, histtype='step', color=col, alpha=.5, label=f'Sample {i}')\n",
    "    ax2.axvline(sample.mean(), lw=2, color=col)\n",
    "    ax2.legend(loc='upper right')\n",
    "    pl.waitforbuttonpress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To figure this out, we could look into probability or statistics theory, but we can also build some intuition ourselves first.\n",
    "\n",
    "Let's create a \"known\" population and sample from it many times, then analyze what we observe.\n",
    "\n",
    "This will allow us to build some intuition about what happens when we sample, and what to expect about a population based on a single sample that came from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Our \"population\": mean=30, std=10')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean,std = 30,10\n",
    "\n",
    "fig,ax = pl.subplots()\n",
    "\n",
    "population = np.random.normal(mean,std,size=100000)\n",
    "# show this histogram, and say: if we can somehow infer this exact population properties using just a single sample,\n",
    "# then we can do our original test -- that's what a one-sample t-test ends up being\n",
    "ax.hist(population, color='k', histtype='step', bins=200, density=True)\n",
    "xs = np.arange(20,40,.01)\n",
    "ys = norm.pdf(xs,mean,std)\n",
    "ax.plot(xs,ys,color='k')\n",
    "ax.set_title(f'Our \"population\": mean={mean}, std={std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to learn what we can expect when sampling from this population.\n",
    "\n",
    "todo: note \"with/without replacement\" - could be a chance to define replacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task:__ from our \"population\", collect 10000 random samples each containing 50 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000 # number of times to sample the population\n",
    "n = 50 # number of observations to take in each sample\n",
    "samples = np.array([np.random.choice(population, size=n) for i in range(N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson #1 of sampling: how do the means of our samples relate to mean of the population?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "TclError",
     "evalue": "can't invoke \"update\" command:  application has been destroyed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-92c6482b629c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Each histogram is a sample of observations\\nWe get one of these when we do an experiment in real life'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mean of observations in a given sample'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitforbuttonpress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhisttype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Frequency'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mwaitforbuttonpress\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    737\u001b[0m     \u001b[0mIf\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoes\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m     \"\"\"\n\u001b[0;32m--> 739\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitforbuttonpress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mwaitforbuttonpress\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   2165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m         \u001b[0mblocking_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockingKeyMouseInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2167\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mblocking_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_default_bbox_extra_artists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/matplotlib/blocking_input.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \"\"\"\n\u001b[1;32m    372\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyormouse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m         \u001b[0mBlockingInput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyormouse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/matplotlib/blocking_input.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, n, timeout)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;31m# Start event loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Run even on exception like ctrl-c\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;31m# Disconnect the callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mstart_event_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   2458\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_looping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2459\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_looping\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtimestep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2460\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2461\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2462\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/matplotlib/backends/_backend_tk.py\u001b[0m in \u001b[0;36mflush_events\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mflush_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_master\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/tkinter/__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[0;34m\"\"\"Enter event loop until all pending events have been processed by Tcl.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'update'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_idletasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \"\"\"Enter event loop until all idle callbacks have been called. This\n",
      "\u001b[0;31mTclError\u001b[0m: can't invoke \"update\" command:  application has been destroyed"
     ]
    }
   ],
   "source": [
    "fig,axs = pl.subplots(2,1,sharex=True,gridspec_kw=dict(hspace=.4))\n",
    "cols = ['red','orange','gold','green','blue','violet','grey','steelblue','pink']\n",
    "\n",
    "pl.waitforbuttonpress()\n",
    "\n",
    "for si,(sample,col) in enumerate(zip(samples,cols)):\n",
    "    axs[0].hist(sample, histtype='step', color=col)\n",
    "    axs[0].axvline(sample.mean(), color=col)\n",
    "    axs[1].axvline(sample.mean(), color=col, alpha=.5)\n",
    "    axs[0].set_xlabel('Observed value')\n",
    "    axs[0].set_ylabel('Frequency')\n",
    "    axs[0].set_title('Each histogram is a sample of observations\\nWe get one of these when we do an experiment in real life')\n",
    "    axs[1].set_xlabel('Mean of observations in a given sample')\n",
    "    pl.waitforbuttonpress()\n",
    "axs[1].hist(samples.mean(axis=1), bins=50, histtype='step', color='k', lw=3)\n",
    "axs[1].set_ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we're beginning to get a sense of how much we can expect our sample mean to reflect the true mean.\n",
    "\n",
    "This distribution is our \"null distribution.\"\n",
    "\n",
    "If we could characterize the center and shape of our null distribution (i.e. its mean and standard deviation), we could compute the probability of observing a single sample from it, as we did in the simpler case before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson #2 of sampling: how does `n` of our samples relate to our estimate of the population mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task\n",
    "\n",
    "for n in range(10,200,50):\n",
    "    samples = np.array([np.random.choice(population, size=n) for i in range(N)])\n",
    "    axs[1].hist(samples.mean(axis=1), bins=50, histtype='step', label=f'n={n}', lw=3, color=pl.cm.Greys(n/200+.1))\n",
    "axs[1].legend(title='n: # of observations in a sample', fontsize='x-small')\n",
    "\n",
    "# normalize those\n",
    "fig,ax = pl.subplots()\n",
    "for n in range(10,200,50):\n",
    "    samples = np.array([np.random.choice(population, size=n) for i in range(N)])\n",
    "    z = (samples-samples.mean(axis=1)[:,None])/(samples.std(axis=1, ddof=1)[:,None])\n",
    "    ax.hist(z.mean(axis=1), density=True, bins=50, histtype='step', label=f'n={n}', lw=3, color=pl.cm.Greys(n/200+.3))\n",
    "pl.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson #3 of sampling: How can we use one sample to infer our null distribution?\n",
    "\n",
    "It turns out that our null distribution of sample means can be inferred from:  \n",
    "* (1) our sample mean\n",
    "* (2) our sample standard deviation ($s$)\n",
    "* (3) our sample size ($n$)\n",
    "\n",
    "Specifically, our null distribution is estimated as a normal distribution with the same mean as our sample, and a standard deviation equal to $\\frac{s}{\\sqrt n}$.  \n",
    "This latter fraction is called the __standard error of the mean__, or SEM.\n",
    "\n",
    "Why do you suppose it's called the standard error of the mean?\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can ask our original question, rephrasing it as: __How much of an outlier is the *difference between our sample mean and the hypothesized mean of 30*?__  \n",
    "\n",
    "And we are now able to precisely specify how we expect this *difference* to be distributed:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'The t-distribution')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "fig,ax = pl.subplots()\n",
    "\n",
    "for n,col in zip([5,10,1000],['r','g','b']):\n",
    "    samples = np.array([np.random.choice(population, size=n) for i in range(N)])\n",
    "    normed = (samples.mean(axis=1)-mean) / (samples.std(axis=1,ddof=1)/np.sqrt(n))\n",
    "    ax.hist(normed, bins=75, histtype='step', label=f'n={n}', density=True, lw=1, color=col)\n",
    "    \n",
    "    # with density true above:\n",
    "    xs = np.arange(-4,4,.01)\n",
    "    ys = t.pdf(xs, n-1)\n",
    "    ax.plot(xs,ys, color=col)\n",
    "ax.legend(fontsize='x-small')\n",
    "ax.set_xlim([-5,5])\n",
    "ax.set_title('The t-distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The single parameter of the t-distribution is the \"degrees of freedom,\" corresponding to sample size - 1.\n",
    "\n",
    "(Overlay t-distribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "__Task__: load in the sample from above and compute a manual t-test to determine whether or not it comes from a population with a mean of 30.\n",
    "\n",
    "*Hint: `scipy.stats` has a module called `t` for t distribution. Consider using the cdf() or sf() functions in that module.*\n",
    "\n",
    "**Bonus:** Complete this without using the `scipy.stats` functions but instead by manually creating the relevant t-distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15390134999644162\n",
      "0.30780269999288323\n"
     ]
    }
   ],
   "source": [
    "# 1. State our hypotheses\n",
    "\n",
    "sample = np.load('sample.npy')\n",
    "\n",
    "# 2. Calculate our test statistic (in this case: t-statistic)\n",
    "n = len(sample)\n",
    "sem = np.std(sample) / n**0.5\n",
    "t_statistic = (30 - sample.mean()) / (sem)\n",
    "\n",
    "# 3. Find a p-value\n",
    "from scipy.stats import t\n",
    "p = t.sf(t_statistic, n-1)\n",
    "\n",
    "print(p) # one-tailed p-value\n",
    "\n",
    "two_tailed_p = p*2\n",
    "print(two_tailed_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our manual t statistic: 1.020\n",
      "Our manual p value: 0.3098181\n"
     ]
    }
   ],
   "source": [
    "# 1. State our hypotheses\n",
    "\n",
    "sample = np.load('sample.npy')\n",
    "\n",
    "# 2. Calculate our test statistic (in this case: t-statistic)\n",
    "# \"critical value: the value of the test statistic past which the test would be significant\"\n",
    "n = len(sample)\n",
    "sem = np.std(sample, ddof=1) / n**0.5\n",
    "t_statistic = np.abs(sample.mean() - 30) / (sem)\n",
    "\n",
    "# 3. Find a p-value\n",
    "from scipy.stats import t\n",
    "p = t.sf(t_statistic, n-1)\n",
    "\n",
    "#print(p) # one-tailed p-value\n",
    "\n",
    "two_tailed_p = p*2\n",
    "print(f'Our manual t statistic: {t_statistic:0.3f}')\n",
    "print(f'Our manual p value: {two_tailed_p:0.7f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy t statistic: -1.020\n",
      "scipy p value: 0.3098181\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "tstat,pvalue = ttest_1samp(a=sample, popmean=30)\n",
    "\n",
    "print(f'scipy t statistic: {tstat:0.3f}')\n",
    "print(f'scipy p value: {pvalue:0.7f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ttest_1samp?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
